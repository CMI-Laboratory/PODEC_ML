{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c99637e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pickle,matplotlib.pyplot as plt, seaborn as sns\n",
    "%matplotlib inline\n",
    "import lightgbm\n",
    "from pandas import DataFrame as df\n",
    "import time,os,sys\n",
    "import random\n",
    "from sklearn import datasets\n",
    "import itertools\n",
    "from matplotlib.colors import ListedColormap\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.datasets import make_moons, make_circles, make_classification, make_blobs, make_checkerboard\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import (RandomForestClassifier, AdaBoostClassifier, \n",
    "                              ExtraTreesClassifier, GradientBoostingClassifier, BaggingClassifier)\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import pickle,matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from pandas import DataFrame as df\n",
    "import time,os,sys\n",
    "import random\n",
    "from sklearn import datasets\n",
    "import itertools\n",
    "from matplotlib.colors import ListedColormap\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.datasets import make_moons, make_circles, make_classification, make_blobs, make_checkerboard\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import (RandomForestClassifier, AdaBoostClassifier, \n",
    "                              ExtraTreesClassifier, GradientBoostingClassifier, BaggingClassifier)\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import xgboost as xgb\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "from sklearn import linear_model\n",
    "from itertools import cycle, islice\n",
    "from matplotlib import pyplot as plt\n",
    "from IPython.display import display, HTML\n",
    "from sklearn.impute import SimpleImputer\n",
    "import pickle,matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from pandas import DataFrame as df\n",
    "import time,os,sys\n",
    "import random\n",
    "from sklearn import datasets\n",
    "import itertools\n",
    "\n",
    "from matplotlib.colors import ListedColormap\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.datasets import make_moons, make_circles, make_classification, make_blobs, make_checkerboard\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import (RandomForestClassifier, AdaBoostClassifier, \n",
    "                              ExtraTreesClassifier, GradientBoostingClassifier, BaggingClassifier)\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import xgboost as xgb\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import numpy as np\n",
    "from scipy import interp\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn import svm, datasets\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "from sklearn import linear_model\n",
    "from itertools import cycle, islice\n",
    "from matplotlib import pyplot as plt\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import RandomizedSearchCV, GridSearchCV\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "import pycaret\n",
    "from pycaret.classification import *\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from numpy import argmax\n",
    "import matplotlib.pyplot as plt\n",
    "if torch.cuda.is_available():\n",
    "    is_cuda = True\n",
    "from torch.utils.data import Dataset,DataLoader\n",
    "from sklearn.model_selection import KFold\n",
    "import torch.nn as nn\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import roc_curve,auc\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import average_precision_score\n",
    "from scipy import interp\n",
    "import json\n",
    "from sklearn.ensemble import ExtraTreesClassifier as et\n",
    "from sklearn.ensemble import GradientBoostingClassifier as gbc\n",
    "import miceforest as mf\n",
    "\n",
    "X=pd.read_csv('20221101_total.csv')\n",
    "X.drop(['Unnamed: 0'],axis=1,inplace=True)\n",
    "X.drop([\"rSO2_avail\",\"EEG_avail\",\"MAP_avail\",\"CVP_avail\",\"HR_avail\",\"mPAP_avail\",\"CI_avail\",\"GAS_avail\",\"SpO2_avail\",\"SvO2_avail\"],axis=1,inplace=True)\n",
    "train_data=X[X['train_val_test']=='train']\n",
    "val_data=X[X['train_val_test']=='val']\n",
    "test_data=X[X['train_val_test']=='test']\n",
    "train_data.reset_index(inplace=True,drop=True)\n",
    "val_data.reset_index(inplace=True,drop=True)\n",
    "test_data.reset_index(inplace=True,drop=True)\n",
    "train_data.drop(['train_val_test'],axis=1,inplace=True)\n",
    "val_data.drop(['train_val_test'],axis=1,inplace=True)\n",
    "test_data.drop(['train_val_test'],axis=1,inplace=True)\n",
    "print(len(train_data),np.sum(train_data['y']))\n",
    "print(len(val_data),np.sum(val_data['y']))\n",
    "print(len(test_data),np.sum(test_data['y']))\n",
    "\n",
    "y_train=train_data['y']\n",
    "X_train=train_data\n",
    "X_train.drop(['y'],axis=1,inplace=True)\n",
    "\n",
    "y_val=val_data['y']\n",
    "X_val=val_data\n",
    "X_val.drop(['y'],axis=1,inplace=True)\n",
    "\n",
    "y_test=test_data['y']\n",
    "X_test=test_data\n",
    "X_test.drop(['y'],axis=1,inplace=True)\n",
    "\n",
    "X_columns=list(X_train.columns)\n",
    "\n",
    "simr=SimpleImputer(missing_values=np.nan,strategy='mean')\n",
    "simr.fit(X_train)\n",
    "X_train=simr.transform(X_train)\n",
    "X_val=simr.transform(X_val)\n",
    "X_test=simr.transform(X_test)\n",
    "\n",
    "X_train=pd.DataFrame(X_train,columns=X_columns)\n",
    "X_val=pd.DataFrame(X_val,columns=X_columns)\n",
    "X_test=pd.DataFrame(X_test,columns=X_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c196061",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seeds(seed):\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "290d151f",
   "metadata": {},
   "source": [
    "# ET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e9b380d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "set_seeds(42)\n",
    "model = et()\n",
    "parameter_space = {\n",
    "    'n_estimators':[100,200],\n",
    "    'criterion':['entropy','gini','log_loss'],\n",
    "    'min_samples_split':[1,2,3],\n",
    "    'min_samples_leaf':[1,2],\n",
    "    'max_depth':[None,2,3],\n",
    "    'max_features':[None,'sqrt','log2']\n",
    "}\n",
    "\n",
    "folds = 4\n",
    "\n",
    "skf = StratifiedKFold(n_splits=folds, shuffle = True)\n",
    "\n",
    "              \n",
    "random_search = GridSearchCV(model, parameter_space, scoring=['roc_auc','average_precision'],verbose=2, return_train_score=True, cv=skf.split(X_train,y_train),refit=False)\n",
    "\n",
    "# Here we go\n",
    "#start_time = timer(None) # timing starts from this point for \"start_time\" variable\n",
    "\n",
    "random_search.fit(X_train, y_train)\n",
    "#timer(start_time) # timing ends here for \"start_time\" variable\n",
    "\n",
    "#print(random_search.best_estimator_)\n",
    "#print(random_search.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01a49de0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.DataFrame(random_search.cv_results_)\n",
    "df[df[\"rank_test_roc_auc\"]==1][[\"params\",\"mean_test_roc_auc\",\"std_test_roc_auc\",\"mean_test_average_precision\",\"std_test_average_precision\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fba617d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df[\"rank_test_roc_auc\"]==1][\"params\"][df[df[\"rank_test_roc_auc\"]==1][\"params\"].index[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61c62375",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e8398bf1",
   "metadata": {},
   "source": [
    "# GBC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2c6f34a",
   "metadata": {},
   "outputs": [],
   "source": [
    "set_seeds(42)\n",
    "model = gbc()\n",
    "parameter_space = {\n",
    "    'loss':['log_loss','deviance','exponential'],\n",
    "    'learning_rate':[0.01,0.1,1],\n",
    "    'n_estimators':[100,200],\n",
    "    'criterion':['friedman_mse','mse','squared_error'],\n",
    "    'min_samples_split':[1,2,3],\n",
    "    'min_samples_leaf':[1,2],\n",
    "    'max_depth':[2,3,4],\n",
    "    'max_features':['auto','sqrt','log2'],\n",
    "\n",
    "\n",
    "}\n",
    "\n",
    "folds = 4\n",
    "\n",
    "skf = StratifiedKFold(n_splits=folds, shuffle = True)\n",
    "\n",
    "              \n",
    "random_search = GridSearchCV(model, parameter_space, scoring=['roc_auc','average_precision'],verbose=2, return_train_score=True, cv=skf.split(X_train,y_train),refit=False)\n",
    "\n",
    "# Here we go\n",
    "#start_time = timer(None) # timing starts from this point for \"start_time\" variable\n",
    "\n",
    "random_search.fit(X_train, y_train)\n",
    "#timer(start_time) # timing ends here for \"start_time\" variable\n",
    "\n",
    "#print(random_search.best_estimator_)\n",
    "#print(random_search.best_score_)\n",
    "df=pd.DataFrame(random_search.cv_results_)\n",
    "df[df[\"rank_test_roc_auc\"]==1][[\"params\",\"mean_test_roc_auc\",\"std_test_roc_auc\",\"mean_test_average_precision\",\"std_test_average_precision\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c665af55",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.DataFrame(random_search.cv_results_)\n",
    "df[df[\"rank_test_roc_auc\"]==1][[\"params\",\"mean_test_roc_auc\",\"std_test_roc_auc\",\"mean_test_average_precision\",\"std_test_average_precision\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f542b02d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df[\"rank_test_roc_auc\"]==1][\"params\"][df[df[\"rank_test_roc_auc\"]==1][\"params\"].index[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b30f6bc3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8eab6aed",
   "metadata": {},
   "source": [
    "# XGB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4214d7fa",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "set_seeds(42)\n",
    "model = xgb.XGBClassifier()\n",
    "parameter_space = {\n",
    "    'gamma':[0,0.001,0.01,0.1,1],\n",
    "    'max_depth':[3,4,5,7,9,12],\n",
    "    'min_child_weight':[1,2,3],\n",
    "    'lambda':[1,3,10,30],\n",
    "    'alpha':[0,0.001,0.01,0.1,1],\n",
    "    'eta':[0.01,0.1,1]\n",
    "}\n",
    "\n",
    "folds = 4\n",
    "\n",
    "skf = StratifiedKFold(n_splits=folds, shuffle = True)\n",
    "\n",
    "              \n",
    "random_search = GridSearchCV(model, parameter_space, scoring=['roc_auc','average_precision'],verbose=2, return_train_score=True, cv=skf.split(X_train,y_train),refit=False)\n",
    "\n",
    "# Here we go\n",
    "#start_time = timer(None) # timing starts from this point for \"start_time\" variable\n",
    "\n",
    "random_search.fit(X_train, y_train)\n",
    "#timer(start_time) # timing ends here for \"start_time\" variable\n",
    "\n",
    "#print(random_search.best_estimator_)\n",
    "#print(random_search.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9563b2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.DataFrame(random_search.cv_results_)\n",
    "df[df[\"rank_test_roc_auc\"]==1][[\"params\",\"mean_test_roc_auc\",\"std_test_roc_auc\",\"mean_test_average_precision\",\"std_test_average_precision\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2f7af89",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df[\"rank_test_roc_auc\"]==1][\"params\"][df[df[\"rank_test_roc_auc\"]==1][\"params\"].index[0]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c30223c4",
   "metadata": {},
   "source": [
    "# RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88d8224e",
   "metadata": {},
   "outputs": [],
   "source": [
    "set_seeds(42)\n",
    "model = RandomForestClassifier()\n",
    "parameter_space = {\n",
    "    'criterion':['log_loss','gini','entropy'],\n",
    "    'n_estimators':[100,200],\n",
    "    'max_depth':[None,1,2],\n",
    "    'min_samples_split':[1,2,3],\n",
    "    'max_features':[None,\"sqrt\",\"log2\"]\n",
    "}\n",
    "\n",
    "folds = 4\n",
    "\n",
    "skf = StratifiedKFold(n_splits=folds, shuffle = True)\n",
    "\n",
    "              \n",
    "random_search = GridSearchCV(model, parameter_space, scoring=['roc_auc','average_precision'],verbose=2, return_train_score=True, cv=skf.split(X_train,y_train),refit=False)\n",
    "\n",
    "# Here we go\n",
    "#start_time = timer(None) # timing starts from this point for \"start_time\" variable\n",
    "\n",
    "random_search.fit(X_train, y_train)\n",
    "#timer(start_time) # timing ends here for \"start_time\" variable\n",
    "\n",
    "#print(random_search.best_estimator_)\n",
    "#print(random_search.best_score_)\n",
    "df=pd.DataFrame(random_search.cv_results_)\n",
    "df[df[\"rank_test_roc_auc\"]==1][[\"params\",\"mean_test_roc_auc\",\"std_test_roc_auc\",\"mean_test_average_precision\",\"std_test_average_precision\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b60dc78",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.DataFrame(random_search.cv_results_)\n",
    "df[df[\"rank_test_roc_auc\"]==1][[\"params\",\"mean_test_roc_auc\",\"std_test_roc_auc\",\"mean_test_average_precision\",\"std_test_average_precision\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21760804",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df[\"rank_test_roc_auc\"]==1][\"params\"][df[df[\"rank_test_roc_auc\"]==1][\"params\"].index[0]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdb8746e",
   "metadata": {},
   "source": [
    "# LGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e21bdff2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "set_seeds(42)\n",
    "model = lightgbm.LGBMClassifier()\n",
    "parameter_space = {\n",
    "    'boosting_type':['gbdt','dart','goss','rf'],\n",
    "    'num_leaves':[25,31,40],\n",
    "    'max_depth':[-1,1,2],\n",
    "    'learning_rate':[0.01,0.1,0.1],\n",
    "    'n_estimators':[100,200],\n",
    "    'reg_alpha':[0,0.01,0.1],\n",
    "    'reg_lambda':[0,0.01,0.1]\n",
    "\n",
    "}\n",
    "\n",
    "folds = 4\n",
    "\n",
    "skf = StratifiedKFold(n_splits=folds, shuffle = True)\n",
    "\n",
    "              \n",
    "random_search = GridSearchCV(model, parameter_space, scoring=['roc_auc','average_precision'],verbose=2, return_train_score=True, cv=skf.split(X_train,y_train),refit=False)\n",
    "\n",
    "# Here we go\n",
    "#start_time = timer(None) # timing starts from this point for \"start_time\" variable\n",
    "\n",
    "random_search.fit(X_train, y_train)\n",
    "#timer(start_time) # timing ends here for \"start_time\" variable\n",
    "\n",
    "#print(random_search.best_estimator_)\n",
    "#print(random_search.best_score_)\n",
    "df=pd.DataFrame(random_search.cv_results_)\n",
    "df[df[\"rank_test_roc_auc\"]==1][[\"params\",\"mean_test_roc_auc\",\"std_test_roc_auc\",\"mean_test_average_precision\",\"std_test_average_precision\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fcfa863",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.DataFrame(random_search.cv_results_)\n",
    "df[df[\"rank_test_roc_auc\"]==1][[\"params\",\"mean_test_roc_auc\",\"std_test_roc_auc\",\"mean_test_average_precision\",\"std_test_average_precision\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df16d55d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df[\"rank_test_roc_auc\"]==1][\"params\"][df[df[\"rank_test_roc_auc\"]==1][\"params\"].index[0]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ba76aa2",
   "metadata": {},
   "source": [
    "# SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eb060b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "set_seeds(42)\n",
    "model = SVC()\n",
    "parameter_space = {\n",
    "    'C' : [0.01,0.1,1,1,10],\n",
    "    'kernel':['linear','poly','rbf','sigmoid']\n",
    "    #'decision_function_shape':['ovo','ovr']\n",
    "}\n",
    "\n",
    "folds = 4\n",
    "\n",
    "skf = StratifiedKFold(n_splits=folds, shuffle = True)\n",
    "\n",
    "              \n",
    "random_search = GridSearchCV(model, parameter_space, scoring=['roc_auc','average_precision'],verbose=2, return_train_score=True, cv=skf.split(X_train,y_train),refit=False)\n",
    "\n",
    "# Here we go\n",
    "#start_time = timer(None) # timing starts from this point for \"start_time\" variable\n",
    "\n",
    "random_search.fit(X_train, y_train)\n",
    "#timer(start_time) # timing ends here for \"start_time\" variable\n",
    "\n",
    "#print(random_search.best_estimator_)\n",
    "#print(random_search.best_score_)\n",
    "df=pd.DataFrame(random_search.cv_results_)\n",
    "df[df[\"rank_test_roc_auc\"]==1][[\"params\",\"mean_test_roc_auc\",\"std_test_roc_auc\",\"mean_test_average_precision\",\"std_test_average_precision\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e108208f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.DataFrame(random_search.cv_results_)\n",
    "df[df[\"rank_test_roc_auc\"]==1][[\"params\",\"mean_test_roc_auc\",\"std_test_roc_auc\",\"mean_test_average_precision\",\"std_test_average_precision\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c736072",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df[\"rank_test_roc_auc\"]==1][\"params\"][df[df[\"rank_test_roc_auc\"]==1][\"params\"].index[0]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "814b5c2d",
   "metadata": {},
   "source": [
    "# LR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3d667bc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "set_seeds(42)\n",
    "model = LogisticRegression()\n",
    "parameter_space = {\n",
    "    'penalty' : ['l1', 'l2'],\n",
    "    'C':[10,3,1,0.3,0.1,0.3,1],\n",
    "    'solver':['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga']\n",
    "\n",
    "}\n",
    "\n",
    "folds = 4\n",
    "\n",
    "skf = StratifiedKFold(n_splits=folds, shuffle = True)\n",
    "\n",
    "              \n",
    "random_search = GridSearchCV(model, parameter_space, scoring=['roc_auc','average_precision'],verbose=2, return_train_score=True, cv=skf.split(X_train,y_train),refit=False)\n",
    "\n",
    "# Here we go\n",
    "#start_time = timer(None) # timing starts from this point for \"start_time\" variable\n",
    "\n",
    "random_search.fit(X_train, y_train)\n",
    "#timer(start_time) # timing ends here for \"start_time\" variable\n",
    "\n",
    "#print(random_search.best_estimator_)\n",
    "#print(random_search.best_score_)\n",
    "df=pd.DataFrame(random_search.cv_results_)\n",
    "df[df[\"rank_test_roc_auc\"]==1][[\"params\",\"mean_test_roc_auc\",\"std_test_roc_auc\",\"mean_test_average_precision\",\"std_test_average_precision\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f253c085",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.DataFrame(random_search.cv_results_)\n",
    "df[df[\"rank_test_roc_auc\"]==1][[\"params\",\"mean_test_roc_auc\",\"std_test_roc_auc\",\"mean_test_average_precision\",\"std_test_average_precision\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "574af65f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df[\"rank_test_roc_auc\"]==1][\"params\"][df[df[\"rank_test_roc_auc\"]==1][\"params\"].index[0]]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
